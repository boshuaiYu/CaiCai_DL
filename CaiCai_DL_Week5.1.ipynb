{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "16Taob-SPfeUXxPrcJdo6T4OfdL8TvhcQ",
      "authorship_tag": "ABX9TyMzXTX6dZ+J12gRCXxFuQGS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boshuaiYu/CaiCai_DL/blob/main/CaiCai_DL_Week5.1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **手动实现训练集和测试集的划分**"
      ],
      "metadata": {
        "id": "JjKy0X2pdya6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import torch"
      ],
      "metadata": {
        "id": "McyOr7jefayl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/drive/MyDrive/Colab Notebooks/week4_function\")\n",
        "from torchLearning import *"
      ],
      "metadata": {
        "id": "Gvri8I7wiRIe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2oq5UmxTLunY"
      },
      "outputs": [],
      "source": [
        "def data_split(features,labels,rate=0.7):\n",
        "  \"\"\"测试集和训练集切分函数\n",
        "\n",
        "  ：param features：输入的特征张量\n",
        "  ：param labels：输入的标签张量\n",
        "  ：param rate：训练集占所有数据的比例\n",
        "  ：return Xtrain, Xtest, ytrain, ytest：返回特征张量的训练集、测试集、及标签向量的训练集、测试集\n",
        "\n",
        "  \"\"\"\n",
        "  num_examples = len(features)\n",
        "  indices = list(range(num_examples))\n",
        "  random.shuffle(indices)\n",
        "  num_train = int(num_examples*rate)\n",
        "  indices_train = torch.tensor(indices[:num_train])\n",
        "  indices_test = torch.tensor(indices[num_train:])\n",
        "  Xtrain = features[indices_train]\n",
        "  ytrain = labels[indices_train]\n",
        "  Xtest = features[indices_test]\n",
        "  ytest = labels[indices_test]\n",
        "  return Xtrain, Xtest, ytrain, ytest"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(420)\n",
        "features,labels = tensorGenReg()\n",
        "Xtrain, Xtest, ytrain, ytest = data_split(features,labels)\n",
        "\n",
        "batch_size = 10\n",
        "lr = 0.03\n",
        "num_epochs = 5\n",
        "w = torch.zeros(3,1,requires_grad=True)\n",
        "\n",
        "net = linreg\n",
        "loss = MSE_loss\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for X,y in data_iter(batch_size,Xtrain,ytrain):\n",
        "    l = loss(net(X,w),y)\n",
        "    l.backward()\n",
        "    sgd(w,lr)"
      ],
      "metadata": {
        "id": "pmpVNmIQf6u8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9i-qI4_gKxD",
        "outputId": "5596c4ab-2729-4b20-c7d1-e68bcb87adda"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2.0005],\n",
              "        [-1.0001],\n",
              "        [ 1.0000]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_loss(torch.mm(Xtrain,w),ytrain) # 训练集结果"
      ],
      "metadata": {
        "id": "Y2U5_DN9gPsr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0d1f716-5b82-4506-e284-5725465d72c2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0001, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MSE_loss(torch.mm(Xtest,w),ytest) # 验证集结果"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TkFj61HnxAc",
        "outputId": "c1613cf8-0616-4220-f07d-330ab0c5ada3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.7272e-05, grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset和DataLoader基本使用方法与数据集切分函数**"
      ],
      "metadata": {
        "id": "m4IbzpVfoBqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Dataset和DataLoader的基本使用方法**\n",
        "\n"
      ],
      "metadata": {
        "id": "ffs4t-eAoVLD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###<font color=\"orange\">**random_split随机划分函数**"
      ],
      "metadata": {
        "id": "ZdQ-7vLlocxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split"
      ],
      "metadata": {
        "id": "l_bioJWFn0Ei"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.arange(12).reshape(4,3)\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUMwUwThooWk",
        "outputId": "f60e6377-f0bc-41b6-f219-871129a0b769"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2],\n",
              "        [ 3,  4,  5],\n",
              "        [ 6,  7,  8],\n",
              "        [ 9, 10, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_split(t,[2,2])  # 第二个参数是数据要切成几份，每一份包含多少数据的列表\n",
        "# 返回的是一个数据生成器"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pqMnExmovH7",
        "outputId": "02078726-ce5e-48d3-b014-3948d1a5647f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<torch.utils.data.dataset.Subset at 0x7fe951b80890>,\n",
              " <torch.utils.data.dataset.Subset at 0x7fe951d49210>]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tr,te in random_split(t,[2,2]):\n",
        "  print(tr,te)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHFI1CZCo8M7",
        "outputId": "55b264ef-00b7-4327-daf5-5363598c70cd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([3, 4, 5]) tensor([6, 7, 8])\n",
            "tensor([0, 1, 2]) tensor([ 9, 10, 11])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###<font color=\"orange\">**Dataset和DataLoader**\n",
        "单独使用TensorDataset打包时必须要保证特征向量时张量形式才可以,具有一定局限性"
      ],
      "metadata": {
        "id": "1mI16g0mpoCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "ym8-oinOzW6Q"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 该类由于是Dataset的子类，则其可以使用DataLoader方法等，不用再使用TensorDataset进行打包，也不用强制性转换为tensor类型\n",
        "class LBCDataset(Dataset):\n",
        "  def __init__(self,data):\n",
        "    self.features = data.data\n",
        "    self.labels = data.target\n",
        "    self.lens = len(data.data)\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    return self.features[index,:],self.labels[index]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.lens\n",
        "\n",
        "# 该类是针对特定数据集的特异化定制"
      ],
      "metadata": {
        "id": "RDM2CtHKpkAT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer as LBC\n",
        "data = LBC()\n",
        "LBC_data = LBCDataset(data)"
      ],
      "metadata": {
        "id": "XIeKqg-6sEul"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LBC_data.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjU7V0uGsvNV",
        "outputId": "23b57c87-760b-497e-ad58-b787f637bca0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
              "        1.189e-01],\n",
              "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
              "        8.902e-02],\n",
              "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
              "        8.758e-02],\n",
              "       ...,\n",
              "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
              "        7.820e-02],\n",
              "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
              "        1.240e-01],\n",
              "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
              "        7.039e-02]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LBC_data.lens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64tcpVm5sxdr",
        "outputId": "5eeb2f25-99db-4bd6-f9a2-550b11a37613"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "569"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LBC_data.__getitem__(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHHhXbtds1vk",
        "outputId": "750252a6-4c61-4c20-c842-ca9ff88ad977"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.969e+01, 2.125e+01, 1.300e+02, 1.203e+03, 1.096e-01, 1.599e-01,\n",
              "        1.974e-01, 1.279e-01, 2.069e-01, 5.999e-02, 7.456e-01, 7.869e-01,\n",
              "        4.585e+00, 9.403e+01, 6.150e-03, 4.006e-02, 3.832e-02, 2.058e-02,\n",
              "        2.250e-02, 4.571e-03, 2.357e+01, 2.553e+01, 1.525e+02, 1.709e+03,\n",
              "        1.444e-01, 4.245e-01, 4.504e-01, 2.430e-01, 3.613e-01, 8.758e-02]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "此时可以使用random_split方法对其进行切分"
      ],
      "metadata": {
        "id": "8jJdiHyiuBqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = int(LBC_data.lens*0.7)\n",
        "num_test = LBC_data.lens - num_train"
      ],
      "metadata": {
        "id": "2QxUSkTetEak"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_train,num_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ1Vws0SuSLT",
        "outputId": "99fbbf1c-f09f-410d-8ba2-371e5cded1e6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(398, 171)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LBC_train, LBC_test = random_split(LBC_data,[num_train,num_test]) # 映射存储\n",
        "# 只有dataset，indices两个属性，dataset用来查看原数据集对象，indices用来查看切分后数据集的每一条数据的index"
      ],
      "metadata": {
        "id": "wOHK4vnfuUnS"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LBC_train.dataset == LBC_data\n",
        "LBC_test.dataset == LBC_data\n",
        "# 返回的是指向原对象"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNUmpBYsugrT",
        "outputId": "b843fd45-783a-4ae1-d2db-6861d1a870ca"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LBC_train.indices[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jfk-iqnYvBld",
        "outputId": "0acf9d3b-d4b4-4b7b-ed78-7f420f78cea0"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[443, 222, 324, 400, 359, 181, 472, 312, 371, 381]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in LBC_train:\n",
        "  print(i)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfbwpgGnwzK2",
        "outputId": "e24224ea-4aca-48e7-9a8d-323abb87576e"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([1.057e+01, 1.832e+01, 6.682e+01, 3.409e+02, 8.142e-02, 4.462e-02,\n",
            "       1.993e-02, 1.111e-02, 2.372e-01, 5.768e-02, 1.818e-01, 2.542e+00,\n",
            "       1.277e+00, 1.312e+01, 1.072e-02, 1.331e-02, 1.993e-02, 1.111e-02,\n",
            "       1.717e-02, 4.492e-03, 1.094e+01, 2.331e+01, 6.935e+01, 3.663e+02,\n",
            "       9.794e-02, 6.542e-02, 3.986e-02, 2.222e-02, 2.699e-01, 6.736e-02]), 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LBC_data.__getitem__(443)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbksL3fkw_R0",
        "outputId": "da100578-77a5-4071-b815-a39765a68548"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.057e+01, 1.832e+01, 6.682e+01, 3.409e+02, 8.142e-02, 4.462e-02,\n",
              "        1.993e-02, 1.111e-02, 2.372e-01, 5.768e-02, 1.818e-01, 2.542e+00,\n",
              "        1.277e+00, 1.312e+01, 1.072e-02, 1.331e-02, 1.993e-02, 1.111e-02,\n",
              "        1.717e-02, 4.492e-03, 1.094e+01, 2.331e+01, 6.935e+01, 3.663e+02,\n",
              "        9.794e-02, 6.542e-02, 3.986e-02, 2.222e-02, 2.699e-01, 6.736e-02]), 1)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataLoader常用参数如下：\n",
        "1.   batch_size：小批量大小\n",
        "2.   shuffle：一般训练集需要乱序，测试集不需要(无意义)\n",
        "3.   num_worker: 启动多少线程进行计算\n",
        "\n"
      ],
      "metadata": {
        "id": "CCGrca8Cxb1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_loader = DataLoader(LBC_train,batch_size=10,shuffle=True)\n",
        "test_loader = DataLoader(LBC_test,batch_size=10,shuffle=False) # 不用shuffle，batch_size一般是test的大小，不用批量"
      ],
      "metadata": {
        "id": "IXYjaI5GxDiE"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LBC_train == train_loader.dataset  # 映射在被加载前的数据集(回溯机制)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq1GovDqyMe1",
        "outputId": "db3d80dd-09d5-4b37-8026-026f2f05bf5e"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 这里值得一提的是，市面上有很多教材在介绍PyTorch深度学习建模过程中的数据集划分过程，会推荐使用<font color=yellow>**scikit-learn**</font>中的<font color=yellow>**train_test_split**</font>函数。该函数是可以非常便捷的完成数据集切分，但这种做法只能用于单机运行的数据，并且切分之后还要调用Dataset、DataLoader模块进行数据封装和加载，切分过程看似简单，但其实会<font color=yellow>**额外占用非常多的存储空间和计算资源**</font>，当进行超大规模数据训练时，所造成的影响会非常明显（当然，也有可能由于数据规模过大，本地无法运行）。因此，为了更好的适应深度学习真实应用场景，在使用包括数据切分等常用函数时，函数使用优先级是:     \n",
        "<center><font color=\"orange\">Pytorch原生函数和类>依据张量及其常用方法手动创建的函数>Scikit-Learn函数"
      ],
      "metadata": {
        "id": "Gl0WP8hV0das"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**2.建模与评估过程**"
      ],
      "metadata": {
        "id": "P6LZ-wwF0K29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "数据准备"
      ],
      "metadata": {
        "id": "aUbunXXC0Upu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 数据生成\n",
        "features,labels = tensorGenReg()\n",
        "features = features[:,:-1]\n",
        "\n",
        "# 创建一个继承Dataset类的数据类\n",
        "class GenData(Dataset):\n",
        "  def __init__(self,features,labels):\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "    self.lens = len(features)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.features[index,:],self.labels[index,:]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.lens\n",
        "# 数据实例化\n",
        "data = GenData(features,labels)\n",
        "# 切分数据集\n",
        "num_train = int(data.lens*0.7)\n",
        "num_test = data.lens - num_train\n",
        "data_train,data_test = random_split(data,[num_train,num_test])\n",
        "#数据加载\n",
        "train_loader = DataLoader(data_train,batch_size=10,shuffle=True)\n",
        "test_loader = DataLoader(data_test,batch_size=10,shuffle=False)"
      ],
      "metadata": {
        "id": "GTxGhobIyqpN"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn,optim\n",
        "batch_size = 10\n",
        "lr = 0.03\n",
        "num_epochs = 3\n",
        "\n",
        "class LR(nn.Module):\n",
        "  def __init__(self,in_features=2,out_features=1):\n",
        "    super(LR,self).__init__()\n",
        "    self.linear = nn.Linear(in_features,out_features)\n",
        "\n",
        "  def forward(self,x):\n",
        "    out = self.linear(x)\n",
        "    return out\n",
        "LR_model = LR()\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.SGD(LR_model.parameters(),lr=lr)\n",
        "\n",
        "def fit(net,criterion,optimizer,batchdata,epochs):\n",
        "  for epoch in range(epochs):\n",
        "    for X,y in batchdata:\n",
        "      yhat = net.forward(X)\n",
        "      loss = criterion(yhat,y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()  "
      ],
      "metadata": {
        "id": "ltrFFz3-1xy3"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(  net=LR_model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    batchdata=train_loader,\n",
        "    epochs=num_epochs\n",
        "    )"
      ],
      "metadata": {
        "id": "rW7HUP5053nU"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F.mse_loss(LR_model(data[data_train.indices][0]),data[data_train.indices][1]) # 训练集上的mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpsRWdMu6LAF",
        "outputId": "af44d5ed-c0ac-4700-de83-83e94bc16f92"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0001, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.mse_loss(LR_model(data[data_test.indices][0]),data[data_test.indices][1]) # 测试集上的mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqYnluOz66yd",
        "outputId": "ac61df4d-4a5a-4df9-881c-ca70f95f3eb1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.8884e-05, grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **实用函数补充**"
      ],
      "metadata": {
        "id": "aHITzBtP7YWl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**数据封装、切分和加载函数**"
      ],
      "metadata": {
        "id": "9dOtwvrw7eXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_loader(features,labels,batch_size=10,rate=0.7):\n",
        "  data = GenData(features,labels)\n",
        "  num_train = int(data.lens * 0.7)\n",
        "  num_test = data.lens - num_train\n",
        "  data_train, data_test = random_split(data,[num_train,num_test])\n",
        "  train_loader = DataLoader(data_train,batch_size=batch_size,shuffle=True)\n",
        "  test_loader = DataLoader(data_test,batch_size=batch_size,shuffle=True)\n",
        "  return (train_loader,test_loader)"
      ],
      "metadata": {
        "id": "Uwqb-NTt7FOt"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**模型训练函数函数**"
      ],
      "metadata": {
        "id": "Oz6DCjGS9CKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(net,criterion,optimizer,batchdata,epochs=3,cla=False):\n",
        "  for epoch in range(epochs):\n",
        "    for X,y in batchdata:\n",
        "      if cla == True:\n",
        "        y = y.flatten().long()   # 分类问题对y进行整数转化\n",
        "      yhat = net.forward(X)\n",
        "      loss = criterion(yhat,y)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ],
      "metadata": {
        "id": "obxgqj9g8Y5V"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse_cal(data_loader,net):\n",
        "  data = data_loader.dataset\n",
        "  X = data[:][0]\n",
        "  y = data[:][1]\n",
        "  yhat = net(X)\n",
        "  return F.mse_loss(yhat,y)"
      ],
      "metadata": {
        "id": "YjK4glfm91nn"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_cal(data_loader,net):\n",
        "  data = data_loader.dataset\n",
        "  X = data[:][0]\n",
        "  y = data[:][1]\n",
        "  zhat = net(X)\n",
        "  soft_z = torch.softmax(zhat,1)\n",
        "  acc_bool = torch.argmax(soft_z,1).flatten() == y.flatten()\n",
        "  acc = torch.mean(acc_bool.float())\n",
        "  return acc"
      ],
      "metadata": {
        "id": "ztCQ--Su-bfd"
      },
      "execution_count": 83,
      "outputs": []
    }
  ]
}